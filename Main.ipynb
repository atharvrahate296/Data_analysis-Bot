{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart analysis assistant : \n",
    "1. takes dataset files  as input(csv,xlsv,txt,json)\n",
    "2. performs operations like data cleaning,feature engineering,transformation,etc. autonoumously "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import kagglehub as kb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv as dtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required data\n",
    "# path = kb.dataset_download(\"rtatman/iris-dataset-json-version\")\n",
    "# print(\"Path to dataset files:\", path)\n",
    "\n",
    "# path = kb.dataset_download(\"jameslko/gun-violence-data\")\n",
    "# print(\"Path to dataset files:\", path)\n",
    "\n",
    "# path = kb.dataset_download(\"juicobowley/drake-lyrics\")\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Datasets/Raw/drake_data.csv\")\n",
    "data.to_excel(\"Datasets/raw/drake_data.xlsx\",sheet_name=\"Sheet1\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_compress_file(file_path):\n",
    "    \"\"\"Load and compress data from CSV, JSON, XLSX, or TXT.\"\"\"\n",
    "    try:\n",
    "        if file_path.endswith(\".csv\"):\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif file_path.endswith(\".json\"):\n",
    "            df = pd.read_json(file_path)\n",
    "        elif file_path.endswith(\".xlsx\"):\n",
    "            df = pd.read_excel(file_path)\n",
    "        elif file_path.endswith(\".txt\"):\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                df = pd.DataFrame({\"text\": f.readlines()})  # Convert text lines to DataFrame\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format!\")\n",
    "\n",
    "        # Convert DataFrame to JSON (keeping size manageable)\n",
    "        json_data = df.head(100).to_json(orient=\"records\")  # Limit to first 100 rows\n",
    "        compressed_data = gzip.compress(json_data.encode())\n",
    "\n",
    "        print(f\"Dataset compressed. Size: {len(compressed_data)} bytes\")\n",
    "        return json_data  # Send JSON instead of raw file\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        return None\n",
    "    \n",
    "files = [\"Datasets/Raw/drake_data.csv\",\"Datasets/Raw/drake_data.json\",\"Datasets/Raw/drake_data.xlsv\",\"Datasets/Raw/drake_lyrics.txt\"]\n",
    "file = []\n",
    "for i in range(0,len(files)):\n",
    "    name = f\"compressed_file{i}\"\n",
    "    file.append(name)\n",
    "    globals()[name] = load_and_compress_file(files[i])\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtn()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found! Check your .env file.\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "def generate_response(query, chat_history):\n",
    "    # Update the system prompt to include chat history\n",
    "    SYS = f'''You are a professional data analysis assistant specializing in extracting insights from structured datasets. \n",
    "    Your role is to help users analyze CSV, JSON, XLSX, and TXT data by preprocessing, summarizing, visualizing key patterns, and providing code snippets for further exploration.\n",
    "\n",
    "    ### Capabilities:\n",
    "    1. **Data Preprocessing:**\n",
    "    - Handle missing values, detect outliers, and normalize data.\n",
    "    - Convert categorical data into numerical formats if needed.\n",
    "    - Identify correlations and anomalies in datasets.\n",
    "    - Always explain why a preprocessing step is necessary before applying it.\n",
    "\n",
    "    2. **Exploratory Data Analysis (EDA):**\n",
    "    - Summarize key statistics (mean, median, mode, min, max, std deviation).\n",
    "    - Identify trends, patterns, and clusters in the data.\n",
    "    - Provide correlation analysis and feature importance.\n",
    "\n",
    "    3. **Data Visualization:**\n",
    "    - Generate histograms, scatter plots, line charts, and heatmaps.\n",
    "    - Represent categorical and numerical relationships visually.\n",
    "    - Highlight key insights using interactive charts when necessary.\n",
    "    - Provide **Python code snippets** for users to run on their local machines.\n",
    "\n",
    "    4. **Insight Generation:**\n",
    "    - Provide natural language explanations of trends and anomalies.\n",
    "    - Suggest potential business or research applications based on the data.\n",
    "    - Recommend further analysis techniques for deeper insights.\n",
    "    - If applicable, provide code to replicate insights using Pandas, Matplotlib, Seaborn, or Plotly.\n",
    "\n",
    "    ### **Example Response Format**\n",
    "    When analyzing data, always include:\n",
    "    1. **Summary of Insights**\n",
    "    2. **Key Observations**\n",
    "    3. **Recommended Actions**\n",
    "    4. **Python Code for Visualization**\n",
    "\n",
    "    ---\n",
    "\n",
    "    ### **Example Response for a User Query**\n",
    "    #### **User:** \"Analyze this sales dataset and provide insights.\"\n",
    "\n",
    "    #### **Response:**\n",
    "    **Summary of Insights:**\n",
    "    - The highest sales were recorded in Q4, indicating a seasonal trend.\n",
    "    - Customers aged 25-34 contribute the most to total revenue.\n",
    "    - Online payments are more popular than cash transactions.\n",
    "\n",
    "    **Key Observations:**\n",
    "    - Sales peaked in December, likely due to holiday shopping.\n",
    "    - The average order value is higher for repeat customers.\n",
    "    - There is a strong correlation between discounts and increased purchases.\n",
    "\n",
    "    **Recommended Actions:**\n",
    "    - Increase marketing efforts in Q4 to maximize seasonal trends.\n",
    "    - Offer loyalty rewards for repeat customers.\n",
    "    - Optimize pricing strategies to balance discount-driven sales.\n",
    "\n",
    "    **Python Code to Visualize Sales Trends:**\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(\"sales_data.csv\")\n",
    "\n",
    "    # Convert date column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # Aggregate sales by month\n",
    "    df['month'] = df['date'].dt.to_period('M')\n",
    "    monthly_sales = df.groupby('month')['sales'].sum()\n",
    "\n",
    "    # Plot sales trends\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.lineplot(x=monthly_sales.index.astype(str), y=monthly_sales.values, marker='o', color='b')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Total Sales\")\n",
    "    plt.title(\"Monthly Sales Trends\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    Here is the conversation history:\\n{chat_history}\\n'''\n",
    "\n",
    "    # Create the model with the updated system prompt\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-2.0-flash\",\n",
    "        system_instruction=SYS\n",
    "    )\n",
    "\n",
    "    # Generate the response using the query\n",
    "    response = model.generate_content(query)\n",
    "    return response.text \n",
    "\n",
    "# Main Function\n",
    "if __name__ == \"__main__\":\n",
    "    chat_history = []\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        exit_msg = [\"exit\", \"end\", \"quit\", \"bye\", \"goodbye\", \"stop\", \"close\", \"shut down\"]\n",
    "\n",
    "        if query.lower() in exit_msg:\n",
    "            print(\"Thank you for using the bot!\")\n",
    "            break\n",
    "\n",
    "        res = generate_response(query, chat_history)\n",
    "        print(\"Bot: \", res)\n",
    "        chat_history.append(f\"You: {query}\\nBot: {res}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
